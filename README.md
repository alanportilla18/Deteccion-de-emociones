# üéØ Detector de Emociones v2.0# üé≠ Detecci√≥n de Emociones con Deep Learning



Una aplicaci√≥n moderna y modular de detecci√≥n de emociones en tiempo real usando Computer Vision y Deep Learning.Sistema avanzado de reconocimiento de emociones en tiempo real utilizando redes neuronales convolucionales (CNN) con arquitectura ResNet y mecanismos de atenci√≥n CBAM.



## üöÄ Caracter√≠sticas Principales## üåü Caracter√≠sticas Principales



- **üé® Interfaz Moderna**: Dise√±o clean y responsivo con componentes personalizados- **Detecci√≥n en tiempo real** de emociones faciales usando modelos de deep learning

- **üîÑ Arquitectura Modular**: C√≥digo organizado en m√≥dulos especializados- **Interfaz gr√°fica moderna** desarrollada con Tkinter

- **üìπ Detecci√≥n en Tiempo Real**: An√°lisis continuo usando c√°mara web- **M√∫ltiples modelos de IA** disponibles para diferentes casos de uso

- **ü§ñ M√∫ltiples Modelos**: Soporte para diferentes arquitecturas de IA- **Generaci√≥n autom√°tica de reportes** en formato PDF

- **üìä Reportes Autom√°ticos**: Generaci√≥n de PDFs con estad√≠sticas detalladas- **M√©tricas detalladas** de rendimiento y estad√≠sticas

- **‚è±Ô∏è Timer Configurable**: Control preciso de intervalos de captura- **Configuraci√≥n flexible** de intervalos de captura

- **üìà M√©tricas Avanzadas**: Estad√≠sticas en tiempo real y an√°lisis de sesiones

## üöÄ Instalaci√≥n y Configuraci√≥n

## üèóÔ∏è Arquitectura Modular

### Prerrequisitos

### Nueva Estructura del Proyecto- Python 3.8 o superior

```- C√°mara web funcional

GUI-emotion/- Entorno virtual (recomendado)

‚îú‚îÄ‚îÄ üìÑ app.py                    # Coordinador principal (simplificado)

‚îú‚îÄ‚îÄ üìÑ app_original.py           # Respaldo del c√≥digo original### Instalaci√≥n

‚îú‚îÄ‚îÄ üìÑ requirements.txt          # Dependencias Python

‚îú‚îÄ‚îÄ üìÑ README.md                 # Documentaci√≥n1. **Clonar o descargar el proyecto**

‚îú‚îÄ‚îÄ üìÅ src/                      # C√≥digo fuente modular   ```bash

‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py           # Inicializaci√≥n del paquete   cd "C:\Users\tu_usuario\Documents\GUI emotion"

‚îÇ   ‚îú‚îÄ‚îÄ üìÑ config.py             # Configuraciones centralizadas   ```

‚îÇ   ‚îú‚îÄ‚îÄ üìÅ core/                 # L√≥gica de negocio

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py2. **Crear entorno virtual**

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ camera.py         # Manejo de c√°mara y video   ```bash

‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìÑ emotion_detector.py # Modelos de IA y predicci√≥n   python -m venv .venv

‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÑ session_manager.py  # Sesiones y estad√≠sticas   .venv\Scripts\activate

‚îÇ   ‚îî‚îÄ‚îÄ üìÅ ui/                   # Interfaz de usuario   ```

‚îÇ       ‚îú‚îÄ‚îÄ üìÑ __init__.py

‚îÇ       ‚îú‚îÄ‚îÄ üìÑ components.py     # Widgets personalizados3. **Instalar dependencias**

‚îÇ       ‚îî‚îÄ‚îÄ üìÑ interface.py      # Interfaz principal   ```bash

‚îú‚îÄ‚îÄ üìÅ models/                   # Modelos de IA (.h5, .keras)   pip install -r requirements.txt

‚îú‚îÄ‚îÄ üìÅ results/                  # Reportes PDF generados   ```

‚îú‚îÄ‚îÄ üìÅ utils/                    # Utilidades (PDF, modelos)

‚îÇ   ‚îú‚îÄ‚îÄ üìÑ model_utils.py        # Funciones de modelo## üéÆ Uso de la Aplicaci√≥n

‚îÇ   ‚îî‚îÄ‚îÄ üìÑ pdf_report.py         # Generaci√≥n de reportes

‚îú‚îÄ‚îÄ üìÅ fer2013/                  # Dataset de entrenamiento### Ejecutar la aplicaci√≥n

‚îî‚îÄ‚îÄ üìÅ graficas/                 # Visualizaciones y gr√°ficas```bash

```python app.py

```

### M√≥dulos Principales

### Flujo de trabajo

#### üîß `src/config.py` - Configuraci√≥n Centralizada1. **Seleccionar modelo**: Elige uno de los 3 modelos disponibles

- **AppConfig**: Configuraci√≥n general de la aplicaci√≥n2. **Iniciar c√°mara**: Presiona "Iniciar C√°mara" para comenzar

- **Colors**: Paleta de colores del dise√±o3. **Detecci√≥n autom√°tica**: El sistema detectar√° emociones seg√∫n el intervalo configurado

- **Fonts**: Tipograf√≠as y tama√±os4. **Ver resultados**: Revisa m√©tricas en tiempo real y genera reportes

- **EmotionConfig**: Configuraci√≥n de emociones y etiquetas

- **UIStyles**: Estilos de componentes UI## üß™ Modelos Disponibles



#### üìπ `src/core/camera.py` - Gesti√≥n de C√°maraEl sistema incluye 3 modelos entrenados espec√≠ficamente conservados:

- **CameraManager**: Captura de video en threading

- **FrameProcessor**: Detecci√≥n facial y procesamiento de im√°genes- **`emotion_model.h5`**: Modelo base de detecci√≥n de emociones

- **`prueba_nuevo_modelo_cnn.h5`**: CNN optimizada para precisi√≥n

#### ü§ñ `src/core/emotion_detector.py` - Inteligencia Artificial- **`resnet_rapido.h5`**: Modelo ResNet optimizado para velocidad

- **EmotionModel**: Carga y manejo de modelos TensorFlow

- **ModelManager**: Gesti√≥n de m√∫ltiples modelos## üìä Funcionalidades



#### üìä `src/core/session_manager.py` - Sesiones y Estad√≠sticas### Detecci√≥n en Tiempo Real

- **SessionManager**: Control de sesiones de detecci√≥n- Procesamiento de video en vivo (~30 FPS)

- **SessionStatistics**: An√°lisis y m√©tricas avanzadas- Clasificaci√≥n de m√∫ltiples emociones

- **EmotionDetection**: Representaci√≥n de detecciones individuales- Confidence score para cada predicci√≥n

- Intervalos de captura configurables

#### üé® `src/ui/components.py` - Componentes UI

- **RoundedButton**: Botones modernos con esquinas redondeadas### An√°lisis y Reportes

- **ModernCard**: Tarjetas con sombra y bordes suaves- Historial completo de sesiones

- **StatusIndicator**: Indicadores de estado con colores- Estad√≠sticas de emociones dominantes

- **ProgressBar**: Barras de progreso personalizadas- M√©tricas de rendimiento del sistema

- Exportaci√≥n a PDF con gr√°ficos

#### üñ•Ô∏è `src/ui/interface.py` - Interfaz Principal

- **EmotionDetectionInterface**: Ventana principal de la aplicaci√≥n### Interfaz de Usuario

- Integraci√≥n de todos los m√≥dulos- Dise√±o moderno e intuitivo

- Manejo de eventos y actualizaciones en tiempo real- Estados visuales din√°micos

- Controles accesibles

## üìã Requisitos del Sistema- Feedback en tiempo real



- **Python**: 3.7+ (recomendado 3.8+)## üìÅ Estructura del Proyecto

- **Sistema Operativo**: Windows 10+, macOS 10.14+, Linux Ubuntu 18.04+

- **Hardware**: C√°mara web, 4GB RAM m√≠nimo```

- **Dependencias**: Ver `requirements.txt`GUI emotion/

‚îú‚îÄ‚îÄ app.py                 # Aplicaci√≥n principal

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n‚îú‚îÄ‚îÄ requirements.txt       # Dependencias del proyecto

‚îú‚îÄ‚îÄ README.md             # Esta documentaci√≥n

### 1. Clonar el Repositorio‚îú‚îÄ‚îÄ models/               # Modelos de IA entrenados

```bash‚îÇ   ‚îú‚îÄ‚îÄ emotion_model.h5

git clone https://github.com/alanportilla18/Detecci-n-de-emociones.git‚îÇ   ‚îú‚îÄ‚îÄ prueba_nuevo_modelo_cnn.h5

cd Detecci-n-de-emociones‚îÇ   ‚îî‚îÄ‚îÄ resnet_rapido.h5

```‚îú‚îÄ‚îÄ utils/                # Utilidades del proyecto

‚îÇ   ‚îú‚îÄ‚îÄ model_utils.py    # Funciones de carga y procesamiento de modelos

### 2. Configurar Entorno Virtual‚îÇ   ‚îî‚îÄ‚îÄ pdf_report.py     # Generaci√≥n de reportes PDF

```bash‚îú‚îÄ‚îÄ fer2013/              # Dataset de prueba

# Crear entorno virtual‚îÇ   ‚îú‚îÄ‚îÄ test/            # Im√°genes de prueba por emoci√≥n

python -m venv .venv‚îÇ   ‚îî‚îÄ‚îÄ train/           # Datos de entrenamiento

‚îî‚îÄ‚îÄ results/             # Reportes generados autom√°ticamente

# Activar entorno virtual```

# Windows PowerShell:

.venv\Scripts\Activate.ps1## üîß Configuraci√≥n Avanzada

# Windows CMD:

.venv\Scripts\activate.bat### Variables de Entorno

# Linux/macOS:La aplicaci√≥n se configura autom√°ticamente, pero puedes personalizar:

source .venv/bin/activate

```- **Intervalo de captura**: Ajustable desde la interfaz (0.1 - 10 segundos)

- **Resoluci√≥n de c√°mara**: Detectada autom√°ticamente

### 3. Instalar Dependencias- **Modelos**: Carga autom√°tica desde la carpeta `models/`

```bash

pip install -r requirements.txt### Dependencias Principales

``````

opencv-python>=4.8    # Procesamiento de video e im√°genes

### 4. Verificar Instalaci√≥nPillow>=9.5          # Manipulaci√≥n de im√°genes

```bashreportlab==3.6.0     # Generaci√≥n de reportes PDF

python app.pytensorflow>=2.12     # Deep learning y modelos de IA

```numpy>=1.23          # Operaciones num√©ricas

```

## üéÆ Gu√≠a de Uso

## üêõ Soluci√≥n de Problemas

### Inicio R√°pido

1. **Ejecutar**: `python app.py`### Error de c√°mara

2. **Seleccionar Modelo**: Elegir de la lista desplegable- Verificar que la c√°mara no est√© siendo usada por otra aplicaci√≥n

3. **Configurar**: Ajustar intervalo y umbral de confianza- Revisar permisos de acceso a la c√°mara en Windows

4. **Iniciar**: Presionar "Iniciar C√°mara"- Reiniciar la aplicaci√≥n si es necesario

5. **Monitorear**: Ver m√©tricas en tiempo real

6. **Detener**: Presionar "Detener C√°mara" para generar reporte### Error de modelo

- Verificar que los archivos `.h5` est√©n en la carpeta `models/`

### Configuraciones Avanzadas- Comprobar que TensorFlow se instal√≥ correctamente

- Usar el bot√≥n "Recargar" para actualizar la lista de modelos

#### Intervalos de Captura

- **Rango**: 0.1 - 60.0 segundos### Problemas de rendimiento

- **Recomendado**: 2.0 - 5.0 segundos para balance entre precisi√≥n y performance- Aumentar el intervalo de captura si el sistema es lento

- Cerrar otras aplicaciones que usen mucha CPU

#### Umbral de Confianza- Considerar usar el modelo `resnet_rapido.h5` para mejor rendimiento

- **Rango**: 0.0 - 1.0

- **Recomendado**: 0.5 - 0.7 para filtrar detecciones de baja calidad## üìà M√©tricas del Sistema



#### Modelos SoportadosLa aplicaci√≥n monitorea autom√°ticamente:

- **FER2013 (5 clases)**: Enojado, Asco, Feliz, Miedo, Triste- **FPS de c√°mara**: Frames por segundo del video

- **Extendido (6 clases)**: + Neutral- **Tiempo de procesamiento**: Latencia de cada predicci√≥n

- **Completo (7 clases)**: + Sorpresa- **Precisi√≥n del modelo**: Confidence score promedio

- **Avanzado (8 clases)**: + Otro- **Emociones detectadas**: Distribuci√≥n y frecuencia



## üìä Funcionalidades Avanzadas## ü§ù Soporte



### An√°lisis de SesionesPara problemas t√©cnicos o mejoras:

- **Detecciones Totales**: Contador en tiempo real1. Revisar la secci√≥n de soluci√≥n de problemas

- **Duraci√≥n**: Cron√≥metro de sesi√≥n2. Verificar los logs de la aplicaci√≥n

- **Emoci√≥n Dominante**: M√°s frecuente en la sesi√≥n3. Comprobar la instalaci√≥n de dependencias

- **Distribuci√≥n**: Porcentajes por emoci√≥n

- **Confianza Promedio**: Calidad de las detecciones## üìù Notas de Versi√≥n

- **Tasa de Detecci√≥n**: Detecciones por minuto

**Versi√≥n actual**: Aplicaci√≥n estable con interfaz moderna

### Reportes PDF- ‚úÖ Detecci√≥n en tiempo real optimizada

Los reportes incluyen:- ‚úÖ 3 modelos de IA especializados

- üìà **Gr√°ficas de distribuci√≥n** de emociones- ‚úÖ Interfaz de usuario mejorada

- ‚è∞ **L√≠nea de tiempo** de la sesi√≥n- ‚úÖ Generaci√≥n autom√°tica de reportes

- üìã **Estad√≠sticas detalladas** y m√©tricas- ‚úÖ Proyecto limpio y optimizado

- üîç **An√°lisis de calidad** de detecciones

- üìÖ **Metadatos** de sesi√≥n (fecha, duraci√≥n, configuraci√≥n)---



### Temporizador Visual*Desarrollado con Python, TensorFlow y OpenCV para detecci√≥n de emociones en tiempo real.*
- **Countdown**: Cuenta regresiva visual
- **Estados de Color**: Verde ‚Üí Naranja ‚Üí Rojo seg√∫n proximidad
- **Indicadores**: Estado textual del timer
- **Sincronizaci√≥n**: Perfecta con intervalos configurados

## üîß Configuraci√≥n T√©cnica

### Variables de Entorno (config.py)
```python
# Configuraci√≥n de c√°mara
CAMERA_WIDTH = 640
CAMERA_HEIGHT = 480
CAMERA_FPS = 30

# Configuraci√≥n de detecci√≥n
DEFAULT_CAPTURE_INTERVAL = 5.0
DEFAULT_CONFIDENCE_THRESHOLD = 0.5

# Configuraci√≥n de interfaz
WINDOW_WIDTH = 1400
WINDOW_HEIGHT = 900
```

### Personalizaci√≥n de Colores
```python
class Colors:
    PRIMARY = "#16a04d"      # Verde principal
    SECONDARY = "#ecf0f1"    # Gris claro  
    ACCENT = "#3498db"       # Azul
    SUCCESS = "#27ae60"      # Verde √©xito
    WARNING = "#f39c12"      # Naranja
    DANGER = "#e74c3c"       # Rojo
```

## üêõ Soluci√≥n de Problemas

### Errores Comunes

#### 1. Error de Importaci√≥n de M√≥dulos
```bash
Error importando m√≥dulos: No module named 'src'
```
**Soluci√≥n**: Verificar que est√© ejecutando desde el directorio ra√≠z del proyecto.

#### 2. Error de C√°mara
```bash
[CAMERA ERROR] No se pudo abrir la c√°mara
```
**Soluci√≥n**: 
- Verificar que la c√°mara no est√© siendo usada por otra aplicaci√≥n
- Probar cambiar el √≠ndice de c√°mara en configuraci√≥n
- Verificar permisos de c√°mara del sistema

#### 3. Error de Modelo
```bash
[MODEL ERROR] Error cargando modelo
```
**Soluci√≥n**:
- Verificar que el archivo `.h5` est√© completo y no corrupto
- Verificar compatibilidad con versi√≥n de TensorFlow
- Verificar permisos de lectura del archivo

#### 4. Error de PDF
```bash
[SESSION ERROR] Error guardando reporte
```
**Soluci√≥n**:
- Verificar permisos de escritura en carpeta `results/`
- Verificar espacio disponible en disco
- Verificar instalaci√≥n de ReportLab

### Logs y Debugging
Los mensajes de debug incluyen prefijos para f√°cil identificaci√≥n:
- `[CAMERA]`: Eventos de c√°mara
- `[MODEL]`: Carga y predicciones de modelo  
- `[SESSION]`: Manejo de sesiones
- `[TIMER]`: Eventos del temporizador
- `[UI]`: Eventos de interfaz
- `[APP]`: Estados generales de la aplicaci√≥n

## üöÄ Desarrollo y Extensi√≥n

### Agregar Nuevos Modelos
1. Colocar archivo `.h5` o `.keras` en carpeta `models/`
2. El sistema detectar√° autom√°ticamente el n√∫mero de clases
3. Configurar etiquetas en `EmotionConfig` si es necesario

### Crear Nuevos Componentes UI
```python
# En src/ui/components.py
class CustomWidget(tk.Frame):
    def __init__(self, parent, **kwargs):
        super().__init__(parent, **kwargs)
        # Implementaci√≥n del widget
```

### Extender Funcionalidad Core
```python
# En src/core/
class NewModule:
    def __init__(self):
        # Inicializaci√≥n
        pass
```

### Modificar Configuraciones
Editar `src/config.py` para cambiar:
- Colores y temas
- Configuraciones por defecto
- Textos de interfaz
- L√≠mites y validaciones

## üìà Performance y Optimizaci√≥n

### Recomendaciones
- **FPS objetivo**: 30 FPS para video fluido
- **Intervalo de captura**: ‚â•2s para evitar sobrecarga
- **Resoluci√≥n**: 640x480 balance √≥ptimo calidad/performance
- **Umbral confianza**: ‚â•0.5 para filtrar falsos positivos

### Monitoreo
La aplicaci√≥n incluye m√©tricas de performance:
- FPS real de c√°mara
- Tiempo de carga de modelo
- Tasa de √©xito de predicciones
- Uso de memoria (historial limitado)

## üìÑ Licencia

Este proyecto est√° licenciado bajo MIT License.

## üë• Contribuci√≥n

### C√≥mo Contribuir
1. Fork del repositorio
2. Crear branch para nueva funcionalidad
3. Desarrollar siguiendo la arquitectura modular
4. Agregar tests si es necesario
5. Crear Pull Request

### Est√°ndares de C√≥digo
- **Documentaci√≥n**: Docstrings en espa√±ol para todas las funciones
- **Tipado**: Type hints donde sea apropiado
- **Estilo**: Seguir convenciones PEP 8
- **Modularidad**: Mantener separaci√≥n de responsabilidades

## üìû Soporte

### Reportar Issues
Crear issue en GitHub incluyendo:
- Descripci√≥n del problema
- Pasos para reproducir
- Logs relevantes
- Informaci√≥n del sistema

### Contacto
- **GitHub**: [alanportilla18](https://github.com/alanportilla18)
- **Proyecto**: [Detecci-n-de-emociones](https://github.com/alanportilla18/Detecci-n-de-emociones)

---

**üéØ Detector de Emociones v2.0** - Una aplicaci√≥n moderna, modular y escalable para detecci√≥n de emociones en tiempo real.